---
title: "Data Processing Methods"
author: "Dave Bosworth"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document: 
    code_folding: show
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
editor_options: 
  chunk_output_type: console
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_dir = here::here("docs"),
      envir = globalenv()
    )
    })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

Decide on how to process the data for various WQ parameters from [`discretewq`](https://github.com/sbashevkin/discretewq) to be included in the long-term WQ publication.

# Global code and functions

```{r load packages, message = FALSE, warning = FALSE}
# Load packages
library(tidyverse)
library(lubridate)
library(hms)
library(scales)
library(discretewq)
library(deltamapr)
library(sf)
library(leaflet)
library(dtplyr)
library(here)
```

```{r check dir}
# Check if we are in the correct working directory
i_am("Data_processing_methods.Rmd")
```

```{r session info}
# Run session info to display package versions
devtools::session_info()
```

# Import and Prepare Data

```{r import all data}
# Pull in the WQ data from discretewq
df_dwq <-
  wq(
    Sources = c(
      "EMP",
      "STN",
      "FMWT",
      "EDSM",
      "DJFMP",
      "SDO",
      "SKT",
      "SLS",
      "20mm",
      "Suisun",
      "Baystudy",
      "USBR",
      "USGS_SFBS",
      "YBFMP",
      "USGS_CAWSC",
      "NCRO"
    )
  )

# Load Delta Shapefile from Brian and only keep SubRegions east of Carquinez Straight
sf_delta <- R_EDSM_Subregions_Mahardja_FLOAT %>% 
  filter(
    !SubRegion %in% c(
      "Carquinez Strait", 
      "Lower Napa River", 
      "San Francisco Bay",
      "San Pablo Bay",
      "South Bay",
      "Upper Napa River" 
    )
  ) %>% 
  select(SubRegion)
```

```{r prepare wq data overall}
# Prepare WQ data for methods analysis
df_dwq_c <- df_dwq %>% 
  transmute(
    Source,
    Station,
    Latitude,
    Longitude,
    Date = date(Date),
    # Convert Datetime to PST
    Datetime = with_tz(Datetime, tzone = "Etc/GMT+8"),
    Temperature,
    Salinity,
    Secchi,
    Chlorophyll,
    DissAmmonia,
    DissNitrateNitrite,
    DissOrthophos
  ) %>% 
  # Remove records with NA values for all parameters
  filter(
    !if_all(
      c(Temperature, Salinity, Secchi, Chlorophyll, DissAmmonia, DissNitrateNitrite, DissOrthophos),
      is.na
    )
  ) %>% 
  # Remove records without lat-long coordinates
  drop_na(Latitude, Longitude) %>% 
  # Assign SubRegions to the stations
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, remove = FALSE) %>%
  st_transform(crs = st_crs(sf_delta)) %>%
  st_join(sf_delta, join = st_intersects) %>%
  # Remove any data outside our subregions of interest
  filter(!is.na(SubRegion)) %>%
  st_drop_geometry() %>% 
  # Add variables for adjusted calendar year, month, and season
    # Adjusted calendar year: December-November, with December of the previous calendar year
    # included with the following year
  mutate(
    Month = month(Date),
    YearAdj = if_else(Month == 12, year(Date) + 1, year(Date)),
    Season = case_when(
      Month %in% 3:5 ~ "Spring",
      Month %in% 6:8 ~ "Summer",
      Month %in% 9:11 ~ "Fall",
      Month %in% c(12, 1, 2) ~ "Winter"
    )
  ) %>% 
  # Restrict data to 1975-2021
  filter(YearAdj %in% 1975:2021)
```

Now that we've been making updates to the WQ data in the [`discretewq` package](https://github.com/sbashevkin/discretewq), let's take a look at which surveys we can use for the long-term WQ publication. First, we'll look at the temporal scale of all of the surveys available.

```{r temporal all}
# Number of Years for each survey
df_dwq_c %>% 
  distinct(Source, YearAdj) %>% 
  count(Source, name = "NumYears") %>% 
  arrange(desc(NumYears))

# Period of record for each survey
df_dwq_c %>% 
  group_by(Source) %>% 
  summarize(min_date = min(Date), max_date = max(Date)) %>% 
  arrange(min_date)
```

Overall, for all parameters, it looks like all surveys except for SLS, USBR, and EDSM have collected at least 20 years of data. We will assume that these surveys have adequate temporal coverage for the long-term analysis.

```{r filter surveys}
# Only include surveys with adequate temporal coverage
df_dwq_lt <- df_dwq_c %>% filter(!Source %in% c("SLS", "USBR", "EDSM"))
```

Next, we'll prepare the individual parameters separately for further analysis.

```{r prepare indiv parameter}
# Prepare data separately for each parameter
prep_samp_effort <- function(df, param) {
  # Remove any NA values in parameter of interest
  df_param <- df %>% drop_na(.data[[param]])
  
  # Look for any instances when more than 1 data point was collected at a station-day
  df_dups <- df_param %>%
    count(Source, Station, Date) %>% 
    filter(n > 1) %>% 
    select(-n)
  
  # Fix duplicates
  df_dups_fixed <- df_param %>%
    inner_join(df_dups, by = c("Source", "Station", "Date")) %>%
    drop_na(Datetime) %>%
    mutate(
      # Create variable for time
      Time = as_hms(Datetime),
      # Calculate difference from noon for each data point for later filtering
      Noon_diff = abs(hms(hours = 12) - Time)
    ) %>%
    # Use dtplyr to speed up operations
    lazy_dt() %>%
    group_by(Station, Date) %>%
    # Select only 1 data point per station and date, choose data closest to noon
    filter(Noon_diff == min(Noon_diff)) %>%
    # When points are equidistant from noon, select earlier point
    filter(Time == min(Time)) %>%
    ungroup() %>%
    # End dtplyr operation
    as_tibble() %>%
    select(-c(Time, Noon_diff))

  # Add back fixed duplicates and format data frame
  df_param %>%
    anti_join(df_dups, by = c("Source", "Station", "Date")) %>%
    bind_rows(df_dups_fixed) %>%
    select(
      Source,
      Station,
      Latitude,
      Longitude,
      SubRegion,
      YearAdj,
      Month,
      Season,
      Date,
      Datetime,
      .data[[param]]
    )
}

# Create a nested data frame to run functions on
ndf_dwq_lt <- 
  tibble(
    Parameter = c(
      "Temperature",
      "Salinity",
      "Secchi",
      "DissAmmonia",
      "DissNitrateNitrite",
      "DissOrthophos",
      "Chlorophyll"
    ),
    df_data = rep(list(df_dwq_lt), 7)
  ) %>% 
  # Prepare data for each Parameter
  mutate(df_data = map2(df_data, Parameter, .f = prep_samp_effort))
```

# All Stations Map

Next, let's take a look at a map of all stations.

```{r all stations map}
sf_stations <- df_dwq_lt %>% 
  distinct(Source, Station, Latitude, Longitude) %>% 
  # Convert to sf object
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, remove = FALSE)

# Define color palette for Surveys 
color_pal_survey <- colorFactor(palette = "viridis", domain = sf_stations$Source)

# Create map using leaflet
leaflet() %>% 
  addTiles() %>%
  addCircleMarkers(
    data = sf_stations,
    radius = 5,
    fillColor = ~color_pal_survey(Source),
    fillOpacity = 0.8,
    weight = 0.5,
    color = "black",
    opacity = 1,
    label = paste0("Survey: ", sf_stations$Source, ", Station: ", sf_stations$Station)
  ) %>% 
  addLegend(
    position = "topright",
    pal = color_pal_survey,
    values = sf_stations$Source,
    title = "Survey:"
  )
```

Some of the stations from the Suisun Marsh survey are located in small backwater channels and dead-end sloughs which represent a much different habitat than the sampling locations from the other surveys which tend to be in larger, open water channel habitat. We'll keep the stations located in Suisun, Montezuma, and Nurse Sloughs from the Suisun Marsh survey, since they seem to be in the larger channels in the area.

Also, there are a few questionable sampling locations from SKT and YBFMP, but I don't want to dig too deep with these for now.

```{r filter suisun stations}
ndf_dwq_lt_filt <- ndf_dwq_lt %>% 
  mutate(
    df_data = map(
      df_data, 
      ~ filter(.x, !(Source == "Suisun" & !str_detect(Station, "^SU|^MZ|^NS")))
    )
  )
```

# Temporal Coverage

Now let's take a closer look at the temporal data coverage for each Station and parameter.

## Sampling Effort by Station {.tabset .tabset-pills}

```{r create samp effort plots by station}
# Plot function
plot_samp_effort_sta <- function(df) {
  df %>%
    count(Station, YearAdj, name = "num_samples") %>%
    mutate(Station = fct_rev(factor(Station))) %>%
    ggplot(aes(x = YearAdj, y = Station, fill = num_samples)) +
    geom_tile() +
    scale_x_continuous(
      limits = c(1974, 2022),
      breaks = breaks_pretty(20), 
      expand = expansion()
    ) +
    scale_fill_viridis_c(name = "Number of Samples") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
      legend.position = "top"
    )
}

# Create sampling effort by station plots for each Parameter and Source
ndf_dwq_se_sta_plt <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    ndf_data_source = map(df_data, ~ nest(.x, df_data2 = -Source)),
    ndf_data_source = modify_depth(
      ndf_data_source, 
      1, 
      ~ mutate(.x, plt = map(df_data2, plot_samp_effort_sta))
    )
  )
```

```{r print samp effort plots by sta, echo = FALSE, results = "asis", fig.width = 8, fig.height = 11}
for (i in 1:nrow(ndf_dwq_se_sta_plt)) {
  # Create subheadings for each Parameter
  cat("### ", ndf_dwq_se_sta_plt$Parameter[i], " {.tabset .tabset-pills}\n\n")
  for (j in 1:nrow(ndf_dwq_se_sta_plt$ndf_data_source[[i]])) {
    # Create subheadings for each Survey
    cat("#### ", ndf_dwq_se_sta_plt$ndf_data_source[[i]]$Source[j], "\n\n")
    # Print plot
    print(ndf_dwq_se_sta_plt$ndf_data_source[[i]]$plt[[j]])
    cat("\n\n")
  }
}
```

## Remove Sparse Surveys

DJFMP only sampled salinity for the past three years, so we won't include this survey in the salinity analysis. For the USGS-CAWSC stations, only station 11447650 (Sacramento River at Freeport) was sampled on a long-term basis for Dissolved Ammonia, Nitrate+Nitrite, and Orthophosphate. Also, Chlorophyll wasn't sampled consistently at any of the USGS-CAWSC stations. We'll exclude this data from our data set before continuing.

```{r remove sparse surveys}
ndf_dwq_lt_filt <- ndf_dwq_lt_filt %>% 
  mutate(
    df_data = case_when(
      Parameter == "Salinity" ~ modify_depth(df_data, 1, ~ filter(.x, Source != "DJFMP")),
      str_detect(Parameter, "^Diss") ~ modify_depth(
        df_data, 1, ~ filter(.x, !(Source == "USGS_CAWSC" & Station != "USGS-11447650"))),
      Parameter == "Chlorophyll" ~ modify_depth(df_data, 1, ~ filter(.x, Source != "USGS_CAWSC")),
      TRUE ~ df_data
    )
  )
```

## Sampling Effort by Subregion {.tabset .tabset-pills}

Before we start removing subregions and stations, let's take a look at the sampling effort for each subregion and parameter combination.

```{r create samp effort plots by subregion}
# Plot function
plot_samp_effort_subreg <- function(df) {
  # Create a vector of all possible SubRegions
  subreg_all <- sf_delta %>% distinct(SubRegion) %>% pull(SubRegion)
  
  # Create plot
  df %>%
    count(SubRegion, YearAdj, name = "num_samples") %>%
    mutate(SubRegion = fct_rev(factor(SubRegion, levels = subreg_all))) %>% 
    ggplot(aes(x = YearAdj, y = SubRegion, fill = num_samples)) +
    geom_tile() +
    scale_x_continuous(
      limits = c(1974, 2022),
      breaks = breaks_pretty(20), 
      expand = expansion()
    ) +
    scale_y_discrete(drop = FALSE) +
    scale_fill_viridis_c(name = "Number of Samples") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
      legend.position = "top"
    )
}

# Create sampling effort by SubRegion plots for each Parameter
ndf_dwq_se_subreg_plt <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    plt = map(df_data, plot_samp_effort_subreg)
  )
```

```{r print samp effort plots by subreg, echo = FALSE, results = "asis", fig.width = 8, fig.height = 8}
for (i in 1:nrow(ndf_dwq_se_subreg_plt)) {
  # Create subheadings for each Parameter
  cat("### ", ndf_dwq_se_subreg_plt$Parameter[i], "\n\n")
  # Print plot
  print(ndf_dwq_se_subreg_plt$plt[[i]])
  cat("\n\n")
}
```

# Filter Subregions

```{r define num years threshold, include = FALSE}
num_yrs_threshold <- round(length(1975:2021) * 0.75)
```

Since not all of the subregions were sampled consistently from 1975-2021, we'll only keep the Subregions that contain data for at least 75% of the `r length(1975:2021)` years between 1975 to 2021, which is `r num_yrs_threshold` years. We'll first remove the subregions that have data for less than `r num_yrs_threshold` years overall before considering the temporal coverage by month.

```{r filter subregions overall}
ndf_dwq_lt_filt <- ndf_dwq_lt_filt %>% 
  mutate(
    df_subreg = map(
      df_data, 
      ~ distinct(.x, SubRegion, YearAdj) %>% 
        count(SubRegion, name = "NumYears") %>% 
        filter(NumYears >= num_yrs_threshold) # num_yrs_threshold = 35
    ),
    df_data_filt = map2(
      df_data, df_subreg, 
      ~ filter(.x, SubRegion %in% unique(.y$SubRegion))
    )
  )
```

## Sampling Effort by Month {.tabset .tabset-pills}

Let's take a look at the sampling effort for each subregion and parameter by month for the remaining subregions.

```{r create samp effort plots by month}
# Plot function
plot_samp_effort_month <- function(df) {
  df %>%
    mutate(Month = fct_rev(month(Date, label = TRUE))) %>% 
    count(SubRegion, YearAdj, Month, name = "num_samples") %>%
    ggplot(aes(x = YearAdj, y = Month, fill = num_samples)) +
    geom_tile() +
    facet_wrap(vars(SubRegion)) +
    scale_x_continuous(
      limits = c(1974, 2022),
      breaks = breaks_pretty(10), 
      expand = expansion()
    ) +
    scale_fill_viridis_c(name = "Number of Samples") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
      legend.position = "top"
    )
}

# Create sampling effort by Month plots for each Parameter
ndf_dwq_se_month_plt <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    plt = map(df_data_filt, plot_samp_effort_month)
  )
```

```{r print samp effort plots by month, echo = FALSE, results = "asis", fig.width = 9, fig.height = 11}
for (i in 1:nrow(ndf_dwq_se_month_plt)) {
  # Create subheadings for each Parameter
  cat("### ", ndf_dwq_se_month_plt$Parameter[i], "\n\n")
  # Print plot
  print(ndf_dwq_se_month_plt$plt[[i]])
  cat("\n\n")
}
```

## Filter by Month

Now, we will require that a subregion has data for at least `r num_yrs_threshold` years for each **month** to make sure that the months were sampled adequately.

```{r filter subregions by month}
ndf_dwq_lt_filt <- ndf_dwq_lt_filt %>% 
  mutate(
    df_subreg_month = map(
      df_data_filt, 
      ~ distinct(.x, SubRegion, YearAdj, Month) %>% 
        count(SubRegion, Month, name = "NumYears") %>% 
        group_by(SubRegion) %>% 
        filter(min(NumYears) >= num_yrs_threshold) %>%  # num_yrs_threshold = 35
        ungroup()
    ),
    df_data_filt_month = map2(
      df_data_filt, df_subreg_month, 
      ~ filter(.x, SubRegion %in% unique(.y$SubRegion))
    )
  )
```

### View Results {.tabset .tabset-pills}

Let's take a look at which subregions remain and how it compares to what we did in the long-term analysis for the 2021 Drought Synthesis report.

```{r prepare results subregion by month, message = FALSE}
# Import Chlorophyll data used in the long-term analysis for the 2021 Drought
  # Synthesis report and add lat-long coordinates
df_chla_ds_lt <- read_csv(here("chla_data_stats_LT2.csv")) %>% 
  mutate(Source = if_else(Source == "USGS-SFBRMP", "USGS_SFBS", Source)) %>% 
  left_join(st_drop_geometry(sf_stations), by = c("Source", "Station"))

# Pull out SubRegions for each parameter after using the filtering steps by month
ndf_subreg_month <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    df_subreg = map(df_subreg_month, ~ distinct(.x, SubRegion))
  ) %>% 
  add_row(
    Parameter = c(
      "AllSubregions", 
      "DrtSynthWQ",
      "DrtSynthNutr",
      "DrtSynthChla"
    ),
    df_subreg = list(
      # Add all possible SubRegions from sf_delta
      sf_delta %>% distinct(SubRegion),
      # Add SubRegions used in the long-term analysis for the 2021 Drought Synthesis report
      DroughtData::raw_wq_1975_2021 %>% distinct(SubRegion),
      DroughtData::raw_nutr_1975_2021 %>% distinct(SubRegion),
      df_chla_ds_lt %>% distinct(SubRegion)
    ),
    .before = 1
  )

# Create a list of character vectors to define the suffixes for the reducing full join
lst_suffix_month <- map(ndf_subreg_month$Parameter[-1], ~ c("", paste0("_", .x)))

# Create a custom function for the full join
join_subregions <- function(df1, df2, suff) {
  full_join(df1, df2, by = "SubRegion", suffix = suff, keep = TRUE)
}

# Define parameter levels
param_levels <- c(
  "DrtSynthWQ",
  "Temperature",
  "Salinity",
  "Secchi",
  "DrtSynthNutr",
  "DissAmmonia",
  "DissNitrateNitrite",
  "DissOrthophos",
  "DrtSynthChla",
  "Chlorophyll"
)

# Run reducing full join and clean up data frame for plotting
df_subreg_month <- reduce2(ndf_subreg_month$df_subreg, lst_suffix_month, join_subregions) %>% 
  mutate(across(contains("_"), ~ if_else(!is.na(.x), "Yes", "No"))) %>% 
  rename_with(~ str_extract(.x, "(?<=_).+"), contains("_")) %>% 
  pivot_longer(cols = -SubRegion, names_to = "Parameter", values_to = "Included") %>% 
  mutate(
    Parameter = factor(Parameter, levels = param_levels),
    SubRegion = fct_rev(factor(SubRegion))
  )

# Create a function for the SubRegion comparison tile plots
plot_reg_comp <- function(df) {
  df %>% 
    ggplot(aes(x = Parameter, y = SubRegion, fill = Included)) + 
    geom_tile()
}
```

#### All Parameters

```{r plot results subregion by month all, echo = FALSE, fig.height = 7, fig.width = 8}
plot_reg_comp(df_subreg_month) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

#### Water Quality Parameters

```{r plot results subregion by month wq, echo = FALSE, fig.height = 6}
df_subreg_month %>% 
  filter(Parameter %in% c("DrtSynthWQ", "Temperature", "Salinity", "Secchi")) %>% 
  plot_reg_comp()
```

#### Nutrients

```{r plot results subregion by month nutr, echo = FALSE, fig.height = 6}
df_subreg_month %>% 
  filter(Parameter %in% c("DrtSynthNutr", "DissAmmonia", "DissNitrateNitrite", "DissOrthophos")) %>% 
  plot_reg_comp()
```

#### Chlorophyll

```{r plot results subregion by month chla, echo = FALSE, fig.height = 6}
df_subreg_month %>% 
  filter(Parameter %in% c("DrtSynthChla", "Chlorophyll")) %>% 
  plot_reg_comp()
```

## Sampling Effort by Season {.tabset .tabset-pills}

Filtering on a month level may be too restrictive, so let's take a look at the sampling effort for each subregion and parameter by season.

```{r create samp effort plots by season}
# Plot function
plot_samp_effort_seas <- function(df) {
  df %>%
    count(SubRegion, YearAdj, Season, name = "num_samples") %>%
    mutate(
      SubRegion = fct_rev(factor(SubRegion)),
      Season = factor(Season, levels = c("Winter", "Spring", "Summer", "Fall"))
    ) %>%
    ggplot(aes(x = YearAdj, y = SubRegion, fill = num_samples)) +
    geom_tile() +
    facet_wrap(vars(Season)) +
    scale_x_continuous(
      limits = c(1974, 2022),
      breaks = breaks_pretty(10), 
      expand = expansion()
    ) +
    scale_fill_viridis_c(name = "Number of Samples") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
      legend.position = "top"
    )
}

# Create sampling effort by Season plots for each Parameter
ndf_dwq_se_seas_plt <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    plt = map(df_data_filt, plot_samp_effort_seas)
  )
```

```{r print samp effort plots by season, echo = FALSE, results = "asis", fig.width = 9, fig.height = 9}
for (i in 1:nrow(ndf_dwq_se_seas_plt)) {
  # Create subheadings for each Parameter
  cat("### ", ndf_dwq_se_seas_plt$Parameter[i], "\n\n")
  # Print plot
  print(ndf_dwq_se_seas_plt$plt[[i]])
  cat("\n\n")
}
```

## Filter by Season

Instead of filtering on a monthly level, let's see what happens if we require that a subregion has data for at least `r num_yrs_threshold` years for each **season** to make sure that the seasons were sampled adequately.

```{r filter subregions by season}
ndf_dwq_lt_filt <- ndf_dwq_lt_filt %>% 
  mutate(
    df_subreg_seas = map(
      df_data_filt, 
      ~ distinct(.x, SubRegion, YearAdj, Season) %>% 
        count(SubRegion, Season, name = "NumYears") %>% 
        group_by(SubRegion) %>% 
        filter(min(NumYears) >= num_yrs_threshold) %>%  # num_yrs_threshold = 35
        ungroup()
    ),
    df_data_filt_seas = map2(
      df_data_filt, df_subreg_seas, 
      ~ filter(.x, SubRegion %in% unique(.y$SubRegion))
    )
  )
```

### View Results {.tabset .tabset-pills}

Again, set's take a look at which subregions remain and how it compares to what we did in the long-term analysis for the 2021 Drought Synthesis report.

```{r prepare results subregion by season, message = FALSE}
# Pull out SubRegions for each parameter after using the filtering steps by season
ndf_subreg_seas <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    df_subreg = map(df_subreg_seas, ~ distinct(.x, SubRegion))
  ) %>% 
  add_row(
    Parameter = c(
      "AllSubregions", 
      "DrtSynthWQ",
      "DrtSynthNutr",
      "DrtSynthChla"
    ),
    df_subreg = list(
      # Add all possible SubRegions from sf_delta
      sf_delta %>% distinct(SubRegion),
      # Add SubRegions used in the long-term analysis for the 2021 Drought Synthesis report
      DroughtData::raw_wq_1975_2021 %>% distinct(SubRegion),
      DroughtData::raw_nutr_1975_2021 %>% distinct(SubRegion),
      df_chla_ds_lt %>% distinct(SubRegion)
    ),
    .before = 1
  )

# Create a list of character vectors to define the suffixes for the reducing full join
lst_suffix_seas <- map(ndf_subreg_seas$Parameter[-1], ~ c("", paste0("_", .x)))

# Run reducing full join and clean up data frame for plotting
df_subreg_seas <- reduce2(ndf_subreg_seas$df_subreg, lst_suffix_seas, join_subregions) %>% 
  mutate(across(contains("_"), ~ if_else(!is.na(.x), "Yes", "No"))) %>% 
  rename_with(~ str_extract(.x, "(?<=_).+"), contains("_")) %>% 
  pivot_longer(cols = -SubRegion, names_to = "Parameter", values_to = "Included") %>% 
  mutate(
    Parameter = factor(Parameter, levels = param_levels),
    SubRegion = fct_rev(factor(SubRegion))
  )
```

#### All Parameters

```{r plot results subregion by season all, echo = FALSE, fig.height = 7, fig.width = 8}
plot_reg_comp(df_subreg_seas) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

#### Water Quality Parameters

```{r plot results subregion by season wq, echo = FALSE, fig.height = 6}
df_subreg_seas %>% 
  filter(Parameter %in% c("DrtSynthWQ", "Temperature", "Salinity", "Secchi")) %>% 
  plot_reg_comp()
```

#### Nutrients

```{r plot results subregion by season nutr, echo = FALSE, fig.height = 6}
df_subreg_seas %>% 
  filter(Parameter %in% c("DrtSynthNutr", "DissAmmonia", "DissNitrateNitrite", "DissOrthophos")) %>% 
  plot_reg_comp()
```

#### Chlorophyll

```{r plot results subregion by season chla, echo = FALSE, fig.height = 6}
df_subreg_seas %>% 
  filter(Parameter %in% c("DrtSynthChla", "Chlorophyll")) %>% 
  plot_reg_comp()
```

# Thoughts

Filtering the subregions by including only those that have data for at least `r num_yrs_threshold` years for each **season** seems to by slightly more permissive than filtering on the monthly level for DissAmmonia and Chlorophyll. Comparing the seasonal approach to the core station approach as seen in [`discretewq` Sampling Effort document](https://interagencyecologicalprogram.github.io/WQ-LT-Publication/Sampling_Effort_discretewq.html), the water quality parameters lose a few subregions overall, and the nutrient and chlorophyll parameters gain a few subregions. 

I am leaning towards using the filtering subregions by the seasonal level approach. If we decide on this as our spatial and temporal filtering method, are all regions covered adequately for the analyses? Let's see...

# Regional coverage

Let's look at the regional coverage assuming that we'll use the seasonal level approach to filter our data, and compare it to what we used in the long-term analysis for the 2021 Drought Synthesis report.

```{r regional coverage}
# Bring in Region-Subregion crosswalk from the Drought Synthesis and add Grant
  # Line Canal and Old River subregion to it
df_regions_mod <- DroughtData:::df_regions %>% 
  distinct(SubRegion, Region) %>% 
  add_row(SubRegion = "Grant Line Canal and Old River", Region = "SouthCentral")

# Pull out Regions for each parameter after using the filtering steps by season,
  # and count number of subregions in each region
ndf_regions <- ndf_dwq_lt_filt %>% 
  transmute(
    Parameter,
    df_region = map(df_data_filt_seas, ~ distinct(.x, SubRegion))
  ) %>% 
  add_row(
    Parameter = c(
      "DrtSynthWQ",
      "DrtSynthNutr",
      "DrtSynthChla"
    ),
    df_region = list(
      # Add SubRegions used in the long-term analysis for the 2021 Drought Synthesis report
      DroughtData::raw_wq_1975_2021 %>% distinct(SubRegion),
      DroughtData::raw_nutr_1975_2021 %>% distinct(SubRegion),
      df_chla_ds_lt %>% distinct(SubRegion)
    ),
    .before = 1
  ) %>% 
  mutate(
    df_region = map(
      df_region,
      ~ left_join(.x, df_regions_mod, by = "SubRegion") %>% 
        count(Region)
    ),
    Parameter = factor(Parameter, levels = param_levels)
  ) %>% 
  arrange(Parameter) %>% 
  mutate(Parameter = as.character(Parameter))

# Print out region counts
for (i in 1:nrow(ndf_regions)) {
  print(ndf_regions$Parameter[i])
  print(ndf_regions$df_region[[i]])
}
```

It looks like all of the same regions are covered as in the long-term analysis for the 2021 Drought Synthesis report with less subregions in some of the regions now. 

